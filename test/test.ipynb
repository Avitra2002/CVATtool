{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/phonavitra/Desktop/dog.jpeg: 480x640 2 dog noses, 142.7ms\n",
      "Speed: 3.5ms preprocess, 142.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "results:[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'dog nose'}\n",
      "obb: None\n",
      "orig_img: array([[[ 56,  95,  74],\n",
      "        [ 56,  95,  74],\n",
      "        [ 56,  95,  74],\n",
      "        ...,\n",
      "        [ 55,  93,  71],\n",
      "        [ 55,  93,  71],\n",
      "        [ 55,  93,  71]],\n",
      "\n",
      "       [[ 56,  95,  74],\n",
      "        [ 56,  95,  74],\n",
      "        [ 56,  95,  74],\n",
      "        ...,\n",
      "        [ 55,  93,  71],\n",
      "        [ 55,  93,  71],\n",
      "        [ 55,  93,  71]],\n",
      "\n",
      "       [[ 56,  95,  74],\n",
      "        [ 56,  95,  74],\n",
      "        [ 56,  95,  74],\n",
      "        ...,\n",
      "        [ 55,  93,  71],\n",
      "        [ 55,  93,  71],\n",
      "        [ 55,  93,  71]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 54,  88,  81],\n",
      "        [ 54,  88,  81],\n",
      "        [ 54,  88,  81],\n",
      "        ...,\n",
      "        [ 50,  97, 125],\n",
      "        [ 50,  97, 125],\n",
      "        [ 50,  97, 125]],\n",
      "\n",
      "       [[ 54,  88,  81],\n",
      "        [ 54,  88,  81],\n",
      "        [ 54,  88,  81],\n",
      "        ...,\n",
      "        [ 50,  96, 127],\n",
      "        [ 50,  96, 127],\n",
      "        [ 50,  96, 127]],\n",
      "\n",
      "       [[ 54,  88,  81],\n",
      "        [ 54,  88,  81],\n",
      "        [ 54,  88,  81],\n",
      "        ...,\n",
      "        [ 50,  96, 127],\n",
      "        [ 50,  96, 127],\n",
      "        [ 50,  96, 127]]], dtype=uint8)\n",
      "orig_shape: (3888, 5184)\n",
      "path: '/Users/phonavitra/Desktop/dog.jpeg'\n",
      "probs: None\n",
      "save_dir: '/Users/phonavitra/Desktop/CVATtool/CVATtool/runs/detect/predict'\n",
      "speed: {'preprocess': 3.5390853881835938, 'inference': 142.7147388458252, 'postprocess': 0.5960464477539062}]\n",
      "Bounding Box Coordinates (x1, y1, x2, y2): tensor([[2601.9155,  833.0687, 3911.6199, 3250.0432],\n",
      "        [1355.4265,  963.9062, 2662.7310, 3190.5598]])\n",
      "Confidence Scores: tensor([0.5381, 0.4682])\n",
      "Class Labels (indices): tensor([0., 0.])\n",
      "Bounding Box 1:\n",
      "Coordinates: [2601.91552734375, 833.0687255859375, 3911.619873046875, 3250.043212890625]\n",
      "Confidence: 0.5381252765655518\n",
      "Label: dog nose\n",
      "Bounding Box 2:\n",
      "Coordinates: [1355.426513671875, 963.9061889648438, 2662.73095703125, 3190.559814453125]\n",
      "Confidence: 0.46824702620506287\n",
      "Label: dog nose\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Initialize a YOLO-World model\n",
    "model = YOLO(\"yolov8s-worldv2.pt\")  # or choose yolov8m/l-world.pt\n",
    "\n",
    "# Define custom classes\n",
    "model.set_classes([\"dog nose\"])\n",
    "\n",
    "# Execute prediction for specified categories on an image\n",
    "results = model.predict(\"/Users/phonavitra/Desktop/dog.jpeg\")\n",
    "\n",
    "print(f'results:{results}')\n",
    "\n",
    "# Access the boxes attribute from the results object\n",
    "boxes = results[0].boxes  # Get the Boxes object from the first result\n",
    "\n",
    "# Extract the box coordinates (xyxy format), confidence scores, and class labels\n",
    "box_coordinates = boxes.xyxy  # Returns tensor of [x1, y1, x2, y2] format\n",
    "confidence_scores = boxes.conf  # Confidence scores for each box\n",
    "class_labels = boxes.cls  # Class labels for each box (as index)\n",
    "\n",
    "# Print the bounding box results\n",
    "print(\"Bounding Box Coordinates (x1, y1, x2, y2):\", box_coordinates)\n",
    "print(\"Confidence Scores:\", confidence_scores)\n",
    "print(\"Class Labels (indices):\", class_labels)\n",
    "\n",
    "# If you want to map the class indices to names, use the 'names' attribute\n",
    "class_names = results[0].names\n",
    "for i, label_idx in enumerate(class_labels):\n",
    "    print(f\"Bounding Box {i + 1}:\")\n",
    "    print(\"Coordinates:\", box_coordinates[i].tolist())\n",
    "    print(\"Confidence:\", confidence_scores[i].item())\n",
    "    print(\"Label:\", class_names[int(label_idx)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n",
      "2.1.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "print(torch.__version__)\n",
    "print(np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvatenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
